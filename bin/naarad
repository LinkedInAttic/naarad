#!/usr/bin/env python
# coding=utf-8
"""
© 2013 LinkedIn Corp. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at  http://www.apache.org/licenses/LICENSE-2.0
 
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
"""

import argparse
import ConfigParser
import datetime
import errno
import logging
import os
import re
import sys
import threading
import time

# Add src directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'src')))

import naarad.utils
from naarad.metrics.metric import Metric
from naarad.metrics.gc_metric import GCMetric
from naarad.metrics.innotop_metric import INNOMetric
from naarad.metrics.sar_metric import SARMetric
from naarad.graphing import dygraphs
from naarad.reporting.report import Report

try:
  from naarad.naarad_imports import metric_classes, graphing_modules, device_type_metrics
except ImportError:
  metric_classes = {}
  graphing_modules = {}

#Naarad pre-defined
metric_classes['GC'] = GCMetric
metric_classes['SAR'] = SARMetric
metric_classes['INNOTOP'] = INNOMetric

graphing_modules['dygraphs'] = dygraphs
graphing_modules['js'] = dygraphs
graphing_modules['javascript'] = dygraphs

version = "0.1"

template_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'templates'))
template_urls = {
    "template:gc": os.path.join(template_dir,"config-gc"),
    "template:sar": os.path.join(template_dir,"config-sar"),
    "template:innotop": os.path.join(template_dir,"config-inno")
    }

logger = logging.getLogger('naarad')

def init_logging(log_level):
  log_file = 'naarad.log'
  # clear the log file
  with open(log_file, 'w'):
    pass

  numeric_level = getattr(logging, log_level.upper(), None) if log_level else logging.INFO
  if not isinstance(numeric_level, int):
    raise ValueError('Invalid log level: %s' % log_level)
  
  logger.setLevel(logging.DEBUG)
  fh = logging.FileHandler(log_file)
  fh.setLevel(logging.DEBUG)
  ch = logging.StreamHandler()
  ch.setLevel(numeric_level)
  formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
  fh.setFormatter(formatter)
  ch.setFormatter(formatter)
  logger.addHandler(fh)
  logger.addHandler(ch)

def read_naarad_templates():
  """
    Read $HOME/.naarad/templates.txt file to read user-defined template keys and related URLs
  """
  home_directory = os.getenv('HOME')
  template_file = os.path.join(home_directory, '.naarad', 'templates.txt')
  logger.info('Adding templates from: ' + template_file)
  if os.path.exists(template_file):
    with open(template_file,'r') as FH:
      for line in FH:
        template, url = [word.strip() for word in line.split()]
        if naarad.utils.is_valid_url(url):
          logger.warning('This line in .naarad/templates.txt does not contain correct URL.' + line + '. Continuing.')
          continue
        if not template.startswith('template:'):
          logger.warning('Template name in this line in .naarad/templates.txt does not follow the convention. Start the name with "template:" please.')
          continue
        if template in template_urls:
          logger.info('Template ' + template + ' exists as pre-defined in Naarad. Overriding the pre-defined template name.')
        logger.info('Adding template ' + template) 
        template_urls[template] = url

def parse_and_plot_single_metrics(metric, graph_timezone, outdir_default, indir_default, metric_string_list, graphing_library, graph_lock):
  metric.graph_timezone = graph_timezone
  if metric.outdir is None:
    metric.outdir = os.path.normpath(outdir_default)
    
  # handling both cases of local file or http download. 
  if not metric.infile.startswith('http://')  \
    and not metric.infile.startswith('https://'): 
    metric.infile = os.path.join(indir_default, metric.infile)
    
  if not metric.ignore:
    if metric.collect():
      if metric.parse():
        metric.calc()
        metric.calculate_stats()
        metric.check_slas()
        graph_lock.acquire()
        metric_html_string = metric.graph(graphing_library)
        graph_lock.release()
        metric_string_list.append(metric_html_string)
      else:
        logger.error('Parsing failed for metric: '  + metric.label)
    else:
      logger.error('Fetch/Collect failed for metric: ' + metric.label)

def transform_ts(start, end, timezone="PDT"):
  """
    Transform time specification to real datetime string.

    :param string start: start timestamp in format YYYY-mm-DD HH:MM:SS or 'end-X((days|day|hours|hour)'
    :param string end: end timestamp in format YYYY-mm-DD HH:MM:SS or 'now'
    :param string timezone: timezone to transform the timestamps into. Should be one of these: (UTC, PST, PDT)
    :return: A tuple of start timestamp and end timestamps transformed from inGraphs like specification to YYYY-mm-DD HH:MM:SS formats
  """
  ts_pattern = "\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}"
  #If timestamp is not in YYYY-mm-DD HH:MM:SS format, then it must be in RRDTool format
  if not re.match(ts_pattern, end):
    if end == "now":
      if timezone in ("PDT", "PST"):
        end_ts = datetime.datetime.now()
      else:
        end_ts = datetime.datetime.utcnow()
      end_ts_str = datetime.datetime.strftime(end_ts, "%Y-%m-%d %H:%M:%S")
    else:
      sys.exit("End timestamp supported with only YYYY-mm-DD HH:MM:SS or 'now' formats. Please fix config. Exiting...")
  else:
    end_ts_str = end
    end_ts = datetime.datetime.strptime(end, "%Y-%m-%d %H:%M:%S")
  if start and not re.match(ts_pattern, start):
    reg_match = re.match("end-(\d+)(days|day|hours|hour)", start)
    if reg_match:
      key = reg_match.group(2)
      val = int(reg_match.group(1))
      if "day" in key:
        delta = datetime.timedelta(days=val)
      elif "hour" in key:
        delta = datetime.timedelta(hours=val)
      start_ts = end_ts - delta
      start_ts_str = datetime.datetime.strftime(start_ts, "%Y-%m-%d %H:%M:%S")
    else:
      #TODO(Ritesh): Add support for minutes and chaining like end-1day2hours5minutes
      sys.exit("Start timestamp supported with only YYYY-mm-DD HH:MM:SS or 'end-x(days|day|hours|hour)' formats. Please fix config. Exiting...")
  else:
    start_ts_str = start
  return (start_ts_str, end_ts_str)

def sanitize_string_section_name(string):
  string = string.replace('/', '_')
  string = string.replace('%', '_')
  return string


def is_valid_metric_name(metric_name):
  """
  check the validity of metric_name in config; the metric_name will be used for creation of sub-dir, so only contains: alphabet, digits , '.', '-' and '_'
  :param str metric_name: metric_name
  :return: True if valid
  """
  reg=re.compile('^[a-zA-Z0-9\.\-\_]+$')
  if reg.match(metric_name) and not metric_name.startswith('.'):
    return True
  else:
    return False
  
def main():
  metrics = []
  crossplots = []
  filler = '' 
  graph_timezone = None
  graphing_library = 'matplotlib'
  variables_dict = {}
  bin_path = os.path.dirname( __file__ )

  arg_parser = argparse.ArgumentParser()

  arg_parser.add_argument('config', help="file with specifications for each metric and graphs")
  arg_parser.add_argument('-i', '--input_dir', help="input directory used to construct full path name of the metric infile")
  arg_parser.add_argument('-o', '--output_dir', help="output directory where the plots and Report.html will be generated")
  arg_parser.add_argument('-r', '--resource_path', help="output sub-directory where resources such as images/svg/csv etc will be stored", default='resources')
  arg_parser.add_argument('-V', '--variables', action="append", help="User defined variables (in form key=value) for substitution in the config file. Config should have the variable names in format %%(key)s")
  arg_parser.add_argument('-s', '--show_config', help="Print config associated with the provided template name", action="store_true")
  arg_parser.add_argument('-l', '--log', help="log level")
  #TODO(Ritesh) : Print a list of all templates supported with descriptions
  #arg_parser.add_argument('-l', '--list_templates', help="List all template configs", action="store_true")

  args = arg_parser.parse_args()

  init_logging(args.log)

  if args:
    read_naarad_templates()
    # Print template config
    if args.show_config:
      tmp_file = naarad.utils.download_file(template_urls[args.config])
      with open(tmp_file, 'r') as FH:
        print "----"
        print FH.read()
      sys.exit("----")

    # Download config if its a URL
    if naarad.utils.is_valid_url(args.config):
      optfile = naarad.utils.download_file(args.config)
    elif args.config.startswith("template:"):
      #Its a template
      if args.config in template_urls.keys():
        logger.info('Using template ' + args.config + ' used from ' + template_urls[args.config] )
        optfile = naarad.utils.download_file(template_urls[args.config])
      else:
        sys.exit("ERROR: Template " + args.config + " not found. Exiting...")
      with open(optfile, 'r') as FH:
        print "Config file used looks like this:"
        print "-------------"
        print FH.read()
        print "-------------"
    else:
      optfile = args.config

    indir_default = args.input_dir
    outdir_default = args.output_dir
    resource_path = args.resource_path
    #user defined variables in form "key=value"
    if args.variables:
      for var in args.variables:
        words = var.split('=')
        variables_dict[words[0]] = words[1]

    if not os.path.exists(optfile):
      sys.exit("ERROR: Config file " + optfile + " doesn't exist. If this is a URL, please use the fully qualified domain name\nExiting....")

    # Parse the config file
    # TODO: Refactor the config parsing code
    config_obj = ConfigParser.ConfigParser(variables_dict)
    # Preserve case http://stackoverflow.com/questions/1611799/preserve-case-in-configparser
    config_obj.optionxform = str
    config_obj.read(optfile)
    for section in config_obj.sections():
      if section == 'GRAPH':
        if config_obj.has_option(section, 'graphing_library'):
          graphing_library = config_obj.get(section, 'graphing_library')
        if config_obj.has_option(section, 'graphs'):
          graphs_string = config_obj.get(section, 'graphs')
          crossplots = graphs_string.split()
        # Supporting both outdir and output_dir
        if config_obj.has_option(section, 'outdir'):
          outdir_default = config_obj.get(section, 'outdir')
        if config_obj.has_option(section, 'output_dir'):
          outdir_default = config_obj.get(section, 'output_dir')
        if config_obj.has_option(section, 'input_dir'):
          indir_default = config_obj.get(section, 'input_dir')
        if config_obj.has_option(section, 'graph_timezone'):
          graph_timezone = config_obj.get(section, 'graph_timezone')
          if graph_timezone not in ("UTC", "PST", "PDT"):
            logger.warn('Unsupported timezone ' + graph_timezone + ' specified in option graph_timezone. Will use UTC instead')
            graph_timezone = "UTC"
      else:
        # Metric sections
        ts_start = None
        ts_end = None
        precision = None
        hostname = "localhost"
        rule_strings = {}
        
        # section name is used to create sub-directories, so enforce it. 
        if not is_valid_metric_name(section):
          logger.critical('The section name of %s is invalid! Only letters, digits, dot(.), dash(-), underscore(_) are allowed' % section)
          sys.exit(0)
          
        try:
          if config_obj.has_option(section, 'hostname'):
            hostname = config_obj.get(section, 'hostname')
            config_obj.remove_option(section, 'hostname')     
          else:
            logger.info('No hostname is found in section %s ' % section)
          
          infile = config_obj.get(section, 'infile')
          config_obj.remove_option(section, 'infile')
          label = sanitize_string_section_name(section)
          if config_obj.has_option(section, 'ts_start'):
            ts_start = config_obj.get(section, 'ts_start')
            config_obj.remove_option(section, 'ts_start')
          if config_obj.has_option(section, 'ts_end'):
            ts_end = config_obj.get(section, 'ts_end')
            config_obj.remove_option(section, 'ts_end')
          if config_obj.has_option(section, 'precision'):
            precision = config_obj.get(section, 'precision')
            config_obj.remove_option(section, 'precision')
          kwargs = dict(config_obj.items(section))
          for key in kwargs.keys():
            if key.endswith('.sla'):
              rule_strings[key.replace('.sla','')] = kwargs[key]
              del kwargs[key]
        except ConfigParser.NoOptionError:
          logger.exception("Exiting.... some mandatory options are missing from the config file in section: " + section)
          sys.exit()
        if section == 'SAR-*':
          sar_metrics = naarad.utils.get_all_sar_objects(metrics, infile, hostname, outdir_default, label, ts_start, ts_end, None)
          if config_obj.has_option(section, 'ignore') and config_obj.getint(section, 'ignore') == 1:
            for metric in sar_metrics:
              metric.ignore = True
          metrics.extend(sar_metrics)
        else:
          #TODO: Make user specify metric_type in config and not infer from section
          metric_type = section.split('-')[0]
          if not metric_type in metric_classes:
            new_metric = Metric(section, infile, hostname, outdir_default, resource_path, label, ts_start, ts_end, rule_strings, **kwargs)
          else:
            new_metric = metric_classes[metric_type](section, infile, hostname, outdir_default, resource_path, label, ts_start, ts_end, rule_strings, **kwargs)
          if config_obj.has_option(section, 'ignore') and config_obj.getint(section, 'ignore') == 1:
            new_metric.ignore = True
          if config_obj.has_option(section, 'calc_metrics'):
            new_metric.calc_metrics = config_obj.get(section, 'calc_metrics')
          new_metric.bin_path = bin_path
          new_metric.precision = precision
          metrics.append(new_metric)

    if outdir_default:
      try:
        os.makedirs(outdir_default)
      except OSError as exeption:
        if exeption.errno != errno.EEXIST:
          raise
      try:
        resource_directory = os.path.join(outdir_default, resource_path)
        os.makedirs(resource_directory)
      except OSError as exeption:
        if exeption.errno != errno.EEXIST:
          raise
      logger.info('Report.html and the plots will be in ' + outdir_default)
    else:
      sys.exit("No output directory defined. Please use option -o, or update the config. Exiting...")
    Metric.graphing_modules = graphing_modules
    Metric.device_types = device_type_metrics
    metric_string_list = []
    if graph_timezone:
      logger.info('X-axis will be displayed in timezone: %s', graph_timezone)
    threads = []
    graph_lock = threading.Lock()
    for metric in metrics:
      thread = threading.Thread(target=parse_and_plot_single_metrics, args=(metric, graph_timezone, outdir_default, indir_default, metric_string_list, graphing_library, graph_lock))
      thread.start()
      threads.append(thread)
    for t in threads:
      t.join()
    if len(crossplots) > 0:
      correlated_plots = naarad.utils.nway_plotting(crossplots, metrics, resource_directory, resource_path, filler)
    else:
      correlated_plots = []
    rpt = Report(None, outdir_default, resource_directory, resource_path, metrics, correlated_plots=correlated_plots)
    rpt.generate()
if __name__ == '__main__':
  main()
